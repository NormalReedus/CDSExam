{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "This cell will always need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:31:28.365288Z",
     "iopub.status.busy": "2020-11-09T20:31:28.362520Z",
     "iopub.status.idle": "2020-11-09T20:31:28.373825Z",
     "shell.execute_reply": "2020-11-09T20:31:28.372369Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Change cwd to this file's dir, so we can use a relative path when saving and loading files:\n",
    "this_dir = os.getcwd()\n",
    "os.chdir(this_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get raw data from EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:31:28.387948Z",
     "iopub.status.busy": "2020-11-09T20:31:28.387948Z",
     "iopub.status.idle": "2020-11-09T20:31:41.105765Z",
     "shell.execute_reply": "2020-11-09T20:31:41.105765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Hacking into the EU mainframe...\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "print('Step 1: Hacking into the EU mainframe...')\n",
    "\n",
    "covid_19_data_url = \"https://opendata.ecdc.europa.eu/covid19/casedistribution/json/\"\n",
    "\n",
    "with urllib.request.urlopen(covid_19_data_url) as input_file:\n",
    "\t# We read the json, but decode it as plaintext, not bytes:\n",
    "\tcovid_19_json = input_file.read().decode('utf-8')\n",
    "\n",
    "\t# We save the fetched data to file:\n",
    "\twith open('../data/input/covid_19_raw.json', 'w') as output_file:\n",
    "\t\toutput_file.write(covid_19_json)"
   ]
  },
  {
   "source": [
    "## Optional - Save 1.\n",
    "Save the output of step 1 in `/data/input/` for later use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Optional - Load 1.\n",
    "Load the data needed for step 2, if the data from step 1 has already been saved in `/data/input/`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate deaths and cases per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:31:41.118961Z",
     "iopub.status.busy": "2020-11-09T20:31:41.118961Z",
     "iopub.status.idle": "2020-11-09T20:31:46.974378Z",
     "shell.execute_reply": "2020-11-09T20:31:46.973382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Calculating deaths and cases per capita...\n"
     ]
    }
   ],
   "source": [
    "print('Step 2: Calculating deaths and cases per capita...')\n",
    "\n",
    "def insert_variable_per_cap_columns(covid_19_records):\n",
    "    for record in covid_19_records:\n",
    "        # Skip cases in international waters etc:\n",
    "        if record['popData2019'] == None:\n",
    "            continue\n",
    "\n",
    "        # Insertion of new 'columns':\n",
    "        record['deaths_per_cap'] = record['deaths'] / record['popData2019']\n",
    "        record['cases_per_cap'] = record['cases'] / record['popData2019']\n",
    "\n",
    "\n",
    "with open('../data/input/covid_19_raw.json') as input_file:\n",
    "    covid_19_dict = json.loads(input_file.read())\n",
    "\n",
    "    insert_variable_per_cap_columns(covid_19_dict['records'])\n",
    "\n",
    "    with open('../data/temp/covid_19_vals_per_cap.json', 'w') as output_file:\n",
    "        json.dump(covid_19_dict, output_file)\n"
   ]
  },
  {
   "source": [
    "## Optional - Save 2.\n",
    "Save the output of step 2 in `/data/temp/` for later use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Optional - Load 2.\n",
    "Load the data needed for step 3, if the data from step 2 has already been saved in `/data/temp/`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate max values for the visualiser limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:31:46.991230Z",
     "iopub.status.busy": "2020-11-09T20:31:46.991230Z",
     "iopub.status.idle": "2020-11-09T20:31:47.837328Z",
     "shell.execute_reply": "2020-11-09T20:31:47.838277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Calculating max covid-19 cases and deaths...\n"
     ]
    }
   ],
   "source": [
    "print('Step 3: Calculating max covid-19 cases and deaths...')\n",
    "\n",
    "def remove_top_countries(covid_19_records, sort_by):\n",
    "  # The amount of countries to remove:\n",
    "  remove_amt = 3\n",
    "\n",
    "  # There aren't numbers for all records with these variables:\n",
    "  if sort_by == 'cases_per_cap' or sort_by == 'deaths_per_cap':\n",
    "    covid_19_records = filter(\n",
    "        lambda record: record.get(sort_by), covid_19_records)\n",
    "\n",
    "  # Sorts by the given variable:\n",
    "  sorted_list = sorted(covid_19_records, key=lambda record: record[sort_by])\n",
    "\n",
    "  # Removes the countries with the top numbers\n",
    "  for i in range(remove_amt):\n",
    "    highest_num_country = sorted_list[len(\n",
    "        sorted_list) - 1]['countriesAndTerritories']\n",
    "    sorted_list = [\n",
    "        record for record in sorted_list if record['countriesAndTerritories'] != highest_num_country]\n",
    "  return sorted_list\n",
    "\n",
    "\n",
    "def get_max_vals(covid_19_records):\n",
    "  def get_max_value(variable):\n",
    "    sorted_filtered = remove_top_countries(covid_19_records, sort_by=variable)\n",
    "    max = sorted_filtered[len(sorted_filtered) - 1][variable]\n",
    "    return max\n",
    "\n",
    "  return {\n",
    "      \"cases\": get_max_value('cases'),\n",
    "      \"deaths\": get_max_value('deaths'),\n",
    "      \"cases_per_cap\": get_max_value('cases_per_cap'),\n",
    "      \"deaths_per_cap\": get_max_value('deaths_per_cap')\n",
    "  }\n",
    "\n",
    "# Data has not yet been transformed, since it is easier to loop through before nesting data with dates:\n",
    "with open('../data/temp/covid_19_vals_per_cap.json') as input_file:\n",
    "  covid_19_records = json.loads(input_file.read())['records']\n",
    "\n",
    "  # The max values are not necessarily all for the same country, since they are just used to set the color limits in the visualizer:\n",
    "  max_vals = get_max_vals(covid_19_records)\n",
    "\n",
    "  with open('../data/temp/covid_19_max_vals.json', 'w') as output_file:\n",
    "    json.dump(max_vals, output_file)\n"
   ]
  },
  {
   "source": [
    "## Optional - Save 3.\n",
    "Save the output of step 3 in `/data/temp/` for later use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Optional - Load 3.\n",
    "Load the data needed for step 4, if the data from step 3 have already been saved in `/data/temp/`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform data into a better format for the visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:31:47.847325Z",
     "iopub.status.busy": "2020-11-09T20:31:47.846598Z",
     "iopub.status.idle": "2020-11-09T20:32:02.095358Z",
     "shell.execute_reply": "2020-11-09T20:32:02.094358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Transforming the data to make it easier to work with...\n"
     ]
    }
   ],
   "source": [
    "print('Step 4: Transforming the data to make it easier to work with...')\n",
    "\n",
    "def get_unique_dates(covid_19_list):\n",
    "    used_dates = []\n",
    "\n",
    "    for entry in covid_19_list:\n",
    "        date = entry['dateRep']\n",
    "        if date not in used_dates:\n",
    "            used_dates.append(date)\n",
    "        \n",
    "    return used_dates\n",
    "\n",
    "\n",
    "# The file is opened from the url via the urllib library\n",
    "with open(\"../data/temp/covid_19_vals_per_cap.json\") as input_file:\n",
    "    # The file contains a list \"records\" which holds the information\n",
    "    covid_19_dict = json.loads(input_file.read())\n",
    "\n",
    "    # An array for the finished data is created\n",
    "    data_correct_form = []\n",
    "\n",
    "    # I use my helper function to get an array of dates and run through them.\n",
    "    for date in get_unique_dates(covid_19_dict['records']):\n",
    "        # This is the form i want the data to be in, so i create the template dictionary\n",
    "        date_dict = {'date': date, 'data': []}\n",
    "\n",
    "        # I run through the entire dataset again, and gather all the data points with the corresponding data.\n",
    "        # When found, the entire chunk of data is appended into the countries key in the dictionary.\n",
    "        for entry in covid_19_dict['records']:\n",
    "            if entry['dateRep'] == date:\n",
    "                date_dict['data'].append(entry)\n",
    "\n",
    "        # The entire dictionary is then appended to the list.\n",
    "        data_correct_form.append(date_dict)\n",
    "\n",
    "    covid_19_dict['records'] = data_correct_form\n",
    "\n",
    "    # The end folder is located and the file inside is updated with the new information.\n",
    "    with open('../data/temp/covid_19_transformed.json', 'w') as output_file:\n",
    "        json.dump(covid_19_dict, output_file, indent=2)"
   ]
  },
  {
   "source": [
    "## Optional - Save 4.\n",
    "Save the output of step 4 in `/data/temp/` for later use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Optional - Load 4.\n",
    "Load the data needed for step 5, if the data from step 4 & 3 have already been saved in `/data/temp/`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sorting and filtering out unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-09T20:32:02.124795Z",
     "iopub.status.busy": "2020-11-09T20:32:02.119091Z",
     "iopub.status.idle": "2020-11-09T20:32:07.026039Z",
     "shell.execute_reply": "2020-11-09T20:32:07.026039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Sorting and filtering the data for the visualization...\n"
     ]
    }
   ],
   "source": [
    "print('Step 5: Sorting and filtering the data for the visualization...')\n",
    "\n",
    "# Paths to the json files we need\n",
    "max_vals_path = \"../data/temp/covid_19_max_vals.json\"\n",
    "covid_19_path = \"../data/temp/covid_19_transformed.json\"\n",
    "\n",
    "# The sort function takes a compare function\n",
    "# When sorting, we want to get the earliest date first\n",
    "# The function creates an integer by concatenating year-month-day and sorts on that\n",
    "\n",
    "\n",
    "def compare_function(e):\n",
    "  split_date = e[\"date\"].split(\"/\")\n",
    "  return int(split_date[2] + split_date[1] + split_date[0])\n",
    "\n",
    "\n",
    "# loads both covid_19_max_values.json and covid_19_transformed.json\n",
    "# sorts the records list in the data and merges the two files into a final product\n",
    "# Filtering might be added later\n",
    "with open(max_vals_path) as max_vals, open(covid_19_path) as covid_19_data:\n",
    "  covid_19_dict = json.loads(covid_19_data.read())\n",
    "  max_vals_dict = json.loads(max_vals.read())\n",
    "\n",
    "  covid_19_dict[\"records\"].sort(key=compare_function)\n",
    "\n",
    "  output_dict = {\n",
    "      \"max_vals\": max_vals_dict,\n",
    "      \"records\": covid_19_dict['records']\n",
    "  }\n",
    "\n",
    "  for entry in output_dict['records']:\n",
    "    for data_point in entry['data']:\n",
    "      del data_point['dateRep']\n",
    "      del data_point['day']\n",
    "      del data_point['month']\n",
    "      del data_point['year']\n",
    "      del data_point['popData2019']\n",
    "      del data_point['continentExp']\n",
    "      del data_point['Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
    "\n",
    "  with open(\"../data/output/covid_19_output.json\", \"w\") as output_file:\n",
    "    json.dump(output_dict, output_file, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}